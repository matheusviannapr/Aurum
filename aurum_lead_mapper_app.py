# aurum_lead_mapper_app.py
# Aurum Lead Mapper ‚Äî v1.3.3
# - OSM Overpass POI (alto volume) com mirrors + retry
# - Google Places: Nearby (types) + Text Search (keywords) + Details (telefone/site)
# - Diagn√≥stico de fontes, limpar cache, or√ßamento de tempo ajust√°vel
# - Telhado via Overpass (heur√≠sticas largest/nearest/hybrid)
# - CRM leve (salvar/mesclar/exportar leads)
# - Aba "Maiores Telhados" com persist√™ncia (sem ‚Äúpisca e some‚Äù)

import os, math, time, json
from typing import List, Dict
import pandas as pd
import requests
import streamlit as st
from shapely.geometry import Polygon, MultiPolygon, Point
from pyproj import Transformer
import folium
from streamlit_folium import st_folium
from dotenv import load_dotenv
from collections import Counter

# ================== Setup b√°sico / Tema ==================
load_dotenv()
st.set_page_config(page_title="Aurum Lead Mapper", layout="wide")

st.markdown("""
<style>
.stApp { background:#001f3f; color:#fff; }
.stApp h1, .stApp h2, .stApp h3, .stApp p, .stApp label { color:#fff; }
.stSidebar { background:#003366; }
.stButton>button { background:#FF8C00; color:#fff; border:0; }
a { color:#FFCC66; }
[data-testid="stMetricDelta"] svg { fill:#FFCC66; }
</style>
""", unsafe_allow_html=True)

# ================== Constantes / Config ==================
GOOGLE_PLACES_API_KEY = (os.getenv("GOOGLE_PLACES_API_KEY") or "").strip()
HEADERS = {"User-Agent": "AurumLeadMapper/1.3.3"}

REQUEST_TIMEOUT_S = 12
DETAILS_TIMEOUT_S = 8
SLEEP_BETWEEN_QUERIES = 0.25

# ---------- Cat√°logos ----------
CATEGORIES_PRESETS = {
    "Supermercados / Atacarejos": [
        "supermarket","supermercado","hypermarket","hipermercado","grocery","mercearia",
        "cash and carry","atacarejo","atacado","wholesale club","wholesale","club atacadista",
        "center grocery","food wholesaler","food distributor",
        "Atacad√£o","Assa√≠","Makro","Sam's Club","Carrefour","Carrefour Bairro","P√£o de A√ß√∫car",
        "Extra","Dia","Big","Guanabara","Rede Economia","Mundial","Prezunic","Supermarket",
        "Multimarket","SuperPrix","Super Rede","Costazul","Vianense","Inter Supermercados",
        "Princesa Supermercados","Real Supermercados","Santa Marta","Unidos Supermercados",
        "centro de compras","centro de abastecimento","atacado de alimentos"
    ],
    "Galp√µes / Log√≠stica / F√°bricas": [
        "warehouse","galp√£o","galpao","logistics center","fulfillment center","distribution center",
        "CD","centro de distribui√ß√£o","armaz√©m","armazem","almoxarifado","porto seco",
        "dep√≥sito","deposito","retro√°rea","ZUP","ZPE","condom√≠nio log√≠stico","park log√≠stico",
        "industrial park","parque industrial","distrito industrial","plataforma log√≠stica",
        "transportadora","courier","cross-docking","last mile hub",
        "factory","f√°brica","industria","manufatura","planta industrial","offshore base"
    ],
    "Shoppings / Centros Comerciais": [
        "shopping","shopping center","mall","plaza","boulevard","strip mall","centro comercial",
        "open mall","lifestyle center","outlet","outlet premium",
        "Plaza Niter√≥i","Partage","ParkShopping","Shopping Boulevard","Shopping Nova Am√©rica",
        "Via Parque","Bangu Shopping","Shopping Rio Sul","Shopping Leblon"
    ],
    "Hot√©is / Resorts / Pousadas": [
        "hotel","resort","pousada","hostel","inn","spa resort","eco resort","business hotel",
        "convention hotel","conference center","hotel fazenda",
        "Hilton","Accor","Ibis","Mercure","Novotel","Bourbon","Windsor",
        "Radisson","Sheraton","Marriott","Hampton","Best Western"
    ],
    "Condom√≠nios Comerciais": [
        "business park","office park","commercial condominium","condom√≠nio empresarial",
        "centro empresarial","complexo empresarial","edif√≠cio comercial","torre comercial",
        "centro executivo","coworking","multioffice","tech park","polo tecnol√≥gico"
    ],
    "Postos / Eletropostos": [
        "posto","posto de gasolina","posto de combust√≠veis","gas station","fuel station",
        "GNV","diesel","etanol","Ipiranga","BR","Shell","Ra√≠zen","ALE",
        "eletroposto","charging station","EV charging","carregador veicular",
        "carregamento r√°pido","fast charger","DC fast","Shell Recharge","Zletric","Ultracharge"
    ],
    "Escolas / Universidades / Prefeituras": [
        "school","escola","colegio","col√©gio","universidade","campus","faculdade",
        "instituto federal","CEFET","IFRJ","UFF","UFRJ","UERJ","PUC",
        "prefeitura","secretaria","c√¢mara municipal","autarquia","hospital universit√°rio",
        "centro educacional","sede administrativa","base operacional"
    ],
    "Hospitais / Cl√≠nicas / Sa√∫de": [
        "hospital","maternidade","UPA","pronto socorro","cl√≠nica","policl√≠nica",
        "laborat√≥rio","hemodi√°lise","oncologia","centro m√©dico","complexo hospitalar",
        "Rede D'Or","Unimed","Samaritano","Americas Medical","Lifecenter"
    ],
    "Data Centers / TI Cr√≠tica": [
        "data center","datacenter","teleporto","pops","noc","edge datacenter",
        "telecom hub","central telef√¥nica","central de comuta√ß√£o","subesta√ß√£o de TI"
    ],
    "Frigor√≠ficos / C√¢maras Frias": [
        "frigor√≠fico","frigorifico","c√¢mara fria","camara fria","centro de distribui√ß√£o refrigerado",
        "cold storage","food cold chain","abatedouro"
    ],
    "Aeroportos / Portos / Terminais": [
        "aeroporto","aer√≥dromo","terminal de cargas","terminal portu√°rio","porto",
        "p√°tio regulador","retroporto","esta√ß√£o aduaneira","porto seco"
    ],
}
CATEGORY_WEIGHTS = {
    "Supermercados / Atacarejos": 1.0, "Galp√µes / Log√≠stica / F√°bricas": 1.0,
    "Shoppings / Centros Comerciais": 0.9, "Hot√©is / Resorts / Pousadas": 0.8,
    "Condom√≠nios Comerciais": 0.8, "Postos / Eletropostos": 0.7,
    "Escolas / Universidades / Prefeituras": 0.8,
    "Hospitais / Cl√≠nicas / Sa√∫de": 0.9, "Data Centers / TI Cr√≠tica": 1.0,
    "Frigor√≠ficos / C√¢maras Frias": 0.9, "Aeroportos / Portos / Terminais": 0.8
}
GOOGLE_TYPES_BY_CATEGORY = {
    "Supermercados / Atacarejos": ["supermarket", "grocery_or_supermarket"],
    "Galp√µes / Log√≠stica / F√°bricas": [],
    "Shoppings / Centros Comerciais": ["shopping_mall"],
    "Hot√©is / Resorts / Pousadas": ["lodging"],
    "Condom√≠nios Comerciais": ["establishment"],
    "Postos / Eletropostos": ["gas_station"],
    "Escolas / Universidades / Prefeituras": ["school", "university"],
    "Hospitais / Cl√≠nicas / Sa√∫de": ["hospital"],
    "Data Centers / TI Cr√≠tica": [],
    "Frigor√≠ficos / C√¢maras Frias": [],
    "Aeroportos / Portos / Terminais": ["airport"],
}
OSM_TAGS_BY_CATEGORY = {
    "Supermercados / Atacarejos": [
        ('shop', 'supermarket'), ('shop','wholesale'), ('shop','hypermarket'),
        ('amenity','marketplace'), ('shop','convenience')
    ],
    "Galp√µes / Log√≠stica / F√°bricas": [
        ('building','warehouse'), ('landuse','industrial'), ('building','industrial'), ('landuse','commercial')
    ],
    "Shoppings / Centros Comerciais": [
        ('shop','mall'), ('amenity','marketplace')
    ],
    "Hot√©is / Resorts / Pousadas": [
        ('tourism','hotel'), ('tourism','hostel'), ('tourism','guest_house'), ('tourism','resort')
    ],
    "Condom√≠nios Comerciais": [
        ('building','commercial'), ('office','company'), ('landuse','commercial'),
        ('office','administrative'), ('office','commercial')
    ],
    "Postos / Eletropostos": [
        ('amenity','fuel'), ('amenity','charging_station')
    ],
    "Escolas / Universidades / Prefeituras": [
        ('amenity','school'), ('amenity','university'), ('amenity','college'), ('office','government')
    ],
    "Hospitais / Cl√≠nicas / Sa√∫de": [
        ('amenity','hospital'), ('amenity','clinic'), ('amenity','doctors')
    ],
    "Data Centers / TI Cr√≠tica": [
        ('man_made','works')
    ],
    "Frigor√≠ficos / C√¢maras Frias": [
        ('industrial','food_processing'), ('building','industrial')
    ],
    "Aeroportos / Portos / Terminais": [
        ('aeroway','aerodrome'), ('aeroway','terminal'), ('amenity','ferry_terminal'), ('landuse','harbour')
    ],
}

# ================== Estado ==================
if "df" not in st.session_state: st.session_state.df = None
if "last_params" not in st.session_state: st.session_state.last_params = None
if "saved_leads" not in st.session_state: st.session_state.saved_leads = None
# Persist√™ncia da aba Maiores Telhados
if "big_roofs_df" not in st.session_state: st.session_state.big_roofs_df = None
if "big_roofs_center" not in st.session_state: st.session_state.big_roofs_center = None  # {lat, lon, name}
if "big_roofs_params" not in st.session_state: st.session_state.big_roofs_params = None  # {radius_km, min_area, topn}

# ================== Utilit√°rios geom√©tricos ==================
def get_utm_epsg(lon: float, lat: float) -> int:
    zone = int((lon + 180) // 6) + 1
    return int(f"327{zone:02d}" if lat < 0 else f"326{zone:02d}")

def project_area_m2(geom) -> float:
    try:
        centroid = geom.centroid
        epsg = get_utm_epsg(centroid.x, centroid.y)
        tr = Transformer.from_crs("EPSG:4326", f"EPSG:{epsg}", always_xy=True)
        def _p(coords): return [tr.transform(x, y) for (x, y) in coords]
        if isinstance(geom, Polygon):
            return abs(Polygon(_p(list(geom.exterior.coords)),
                              [_p(list(r.coords)) for r in geom.interiors]).area)
        elif isinstance(geom, MultiPolygon):
            return sum(project_area_m2(p) for p in geom.geoms)
    except Exception:
        return 0.0
    return 0.0

def estimate_kwp(area_m2: float, area_per_kwp: float = 6.0, coverage_ratio: float = 0.6) -> float:
    usable = max(area_m2, 0.0) * coverage_ratio
    return round(usable / (area_per_kwp if area_per_kwp > 0 else 6.0), 2)

def estimate_generation_kwh_year(kwp: float, specific_yield: float = 1500.0) -> float:
    return round(max(kwp, 0.0) * specific_yield, 0)

def haversine_km(lat1, lon1, lat2, lon2):
    R = 6371.0
    phi1, phi2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1); dl = math.radians(lon2 - lon1)
    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dl/2)**2
    return 2 * R * math.asin(math.sqrt(a))

def aurum_score(category: str, area_m2: float, distance_km: float, base_weight: float = 1.0) -> float:
    w_cat = CATEGORY_WEIGHTS.get(category, 0.7)
    area_score = min(area_m2 / 500.0, 1.0)
    dist_score = 1.0 / (1.0 + (distance_km/20.0))
    return round(100.0 * w_cat * area_score * dist_score * base_weight, 1)

# ================== Overpass helpers (mirrors + retry) ==================
OVERPASS_ENDPOINTS = [
    "https://overpass-api.de/api/interpreter",
    "https://overpass.kumi.systems/api/interpreter",
    "https://overpass.openstreetmap.ru/api/interpreter",
    "https://z.overpass-api.de/api/interpreter",
]

def _overpass_call(query: str, timeout_s: int = REQUEST_TIMEOUT_S):
    last_err = None
    for url in OVERPASS_ENDPOINTS:
        try:
            r = requests.post(url, data=query.encode("utf-8"),
                              headers={"Content-Type":"text/plain"},
                              timeout=timeout_s)
            if r.status_code == 200:
                return r.json()
        except Exception as e:
            last_err = e
            time.sleep(0.5)
    if last_err:
        raise last_err
    return {"elements": []}

@st.cache_data(ttl=300, show_spinner=False)
def overpass_buildings_around(lat: float, lon: float, radius_m: int = 200) -> List[Polygon]:
    query = f"""
    [out:json][timeout:25];
    ( way["building"](around:{radius_m},{lat},{lon});
      relation["building"](around:{radius_m},{lat},{lon}); );
    out body; >; out skel qt;
    """
    polys = []
    try:
        data = _overpass_call(query, timeout_s=max(REQUEST_TIMEOUT_S, 20))
        elems = data.get("elements", [])
        nodes = {e["id"]:(e["lon"], e["lat"]) for e in elems if e["type"]=="node"}
        for e in elems:
            if e["type"]=="way" and "nodes" in e:
                coords = [nodes.get(n) for n in e["nodes"] if n in nodes]
                if coords and len(coords) >= 3:
                    try:
                        poly = Polygon(coords)
                        if poly.is_valid and poly.area > 0: polys.append(poly)
                    except Exception:
                        pass
    except Exception:
        pass
    return polys

@st.cache_data(ttl=600, show_spinner=False)
def overpass_buildings_geom_region(lat: float, lon: float, radius_m: int, limit: int = 4000) -> List[Polygon]:
    query = f"""
    [out:json][timeout:90];
    ( way["building"](around:{radius_m},{lat},{lon});
      relation["building"](around:{radius_m},{lat},{lon}); );
    out tags geom {limit};
    """
    try:
        data = _overpass_call(query, timeout_s=max(REQUEST_TIMEOUT_S*3, 30))
    except Exception:
        data = {"elements": []}
    polys: List[Polygon] = []
    for el in data.get("elements", []):
        geom = el.get("geometry")
        if not geom or len(geom) < 3: continue
        try:
            coords = [(pt["lon"], pt["lat"]) for pt in geom]
            poly = Polygon(coords)
            if poly.is_valid and poly.area > 0: polys.append(poly)
        except Exception:
            continue
    return polys

def overpass_poi_search(lat: float, lon: float, radius_m: int, category: str, limit: int = 120) -> List[Dict]:
    tags = OSM_TAGS_BY_CATEGORY.get(category, [])
    if not tags: return []
    filters = " ".join([
        f'node["{k}"="{v}"](around:{radius_m},{lat},{lon});'
        f'way["{k}"="{v}"](around:{radius_m},{lat},{lon});'
        f'relation["{k}"="{v}"](around:{radius_m},{lat},{lon});'
        for k, v in tags
    ])
    query = f"""
    [out:json][timeout:30];
    ( {filters} );
    out center {limit};
    """
    try:
        data = _overpass_call(query, timeout_s=max(REQUEST_TIMEOUT_S, 20))
    except Exception:
        return []
    out = []
    for el in data.get("elements", []):
        if el.get("type") in ("node","way","relation"):
            tg = el.get("tags", {}) or {}
            name = tg.get("name") or str(el.get("id"))
            phone = tg.get("contact:phone") or tg.get("phone")
            website = tg.get("contact:website") or tg.get("website")
            email = tg.get("contact:email") or tg.get("email")
            if el.get("type") == "node":
                latc, lonc = el.get("lat"), el.get("lon")
            else:
                center = el.get("center") or {}
                latc, lonc = center.get("lat"), center.get("lon")
            if latc is None or lonc is None: continue
            out.append({
                "name": name, "address": None, "lat": latc, "lon": lonc,
                "source": "osm_overpass", "osm_id": el.get("id"),
                "class": None, "type": None,
                "phone": phone, "website": website, "email": email,
                "category": category
            })
    return out[:limit]

# ================== Telhado (heur√≠stica) ==================
def pick_roof_polygon_nearest(polygons, poi_lat, poi_lon):
    poi = Point(poi_lon, poi_lat)
    def dist(poly): c = poly.centroid; return haversine_km(poi.y, poi.x, c.y, c.x)
    return min(polygons, key=dist)

def pick_roof_polygon_hybrid(polygons, poi_lat, poi_lon, w_area=0.6, w_near=0.4):
    areas = [project_area_m2(p) for p in polygons]; max_a = max(areas) or 1.0
    dists = [haversine_km(poi_lat, poi_lon, p.centroid.y, p.centroid.x) for p in polygons]; max_d = max(dists) or 1.0
    scores = []
    for a, d in zip(areas, dists):
        area_score = a / max_a
        near_score = 1.0 - (d / max_d)
        scores.append(w_area*area_score + w_near*near_score)
    return polygons[scores.index(max(scores))]

def estimate_rooftop_area_m2(polygons, poi_lat=None, poi_lon=None, mode="largest"):
    if not polygons: return 0.0
    if mode == "nearest" and poi_lat is not None:
        chosen = pick_roof_polygon_nearest(polygons, poi_lat, poi_lon)
    elif mode == "hybrid" and poi_lat is not None:
        chosen = pick_roof_polygon_hybrid(polygons, poi_lat, poi_lon)
    else:
        chosen = max(polygons, key=lambda p: project_area_m2(p))
    return project_area_m2(chosen) if chosen is not None else 0.0

# ================== Geocodifica√ß√£o e Google APIs ==================
@st.cache_data(ttl=86400, show_spinner=False)
def geocode_location(location_name: str, api_key: str = "") -> Dict[str, float]:
    name = (location_name or "").strip()
    if "," in name:
        try:
            a, b = [float(x.strip()) for x in name.split(",")]
            return {"lat": a, "lon": b}
        except Exception:
            pass
    if api_key:
        try:
            url = "https://maps.googleapis.com/maps/api/geocode/json"
            params = {"address": name, "key": api_key, "language": "pt-BR"}
            r = requests.get(url, params=params, headers=HEADERS, timeout=REQUEST_TIMEOUT_S)
            data = r.json()
            if data.get("results"):
                loc = data["results"][0]["geometry"]["location"]
                return {"lat": loc["lat"], "lon": loc["lng"]}
        except Exception:
            pass
    try:
        url = "https://nominatim.openstreetmap.org/search"
        params = {"q": name, "format": "json", "limit": 1}
        r = requests.get(url, params=params, headers=HEADERS, timeout=REQUEST_TIMEOUT_S)
        data = r.json()
        if data:
            return {"lat": float(data[0]["lat"]), "lon": float(data[0]["lon"])}
    except Exception:
        pass
    return {"lat": -22.9, "lon": -43.2}

@st.cache_data(ttl=300, show_spinner=False)
def google_places_text_search(q: str, lat: float, lon: float, radius_m: int, max_results: int, api_key: str) -> List[Dict]:
    if not api_key: return []
    url = "https://maps.googleapis.com/maps/api/place/textsearch/json"
    params = {"query": q, "location": f"{lat},{lon}", "radius": radius_m, "key": api_key, "language": "pt-BR"}
    res = []
    try:
        while True:
            r = requests.get(url, params=params, headers=HEADERS, timeout=REQUEST_TIMEOUT_S)
            data = r.json(); res += data.get("results", [])
            tok = data.get("next_page_token")
            if not tok or len(res) >= max_results: break
            time.sleep(2); params["pagetoken"] = tok
    except Exception:
        pass
    out = []
    for it in res[:max_results]:
        loc = it.get("geometry", {}).get("location", {})
        out.append({
            "name": it.get("name"),
            "address": it.get("formatted_address"),
            "lat": loc.get("lat"), "lon": loc.get("lng"),
            "source": "google_text", "place_id": it.get("place_id"),
            "rating": it.get("rating"), "reviews": it.get("user_ratings_total"),
            "types": it.get("types", [])
        })
    return out

@st.cache_data(ttl=300, show_spinner=False)
def google_places_nearby(lat: float, lon: float, radius_m: int, gtype: str, max_results: int, api_key: str) -> List[Dict]:
    if not api_key or not gtype: return []
    url = "https://maps.googleapis.com/maps/api/place/nearbysearch/json"
    params = {"location": f"{lat},{lon}", "radius": radius_m, "type": gtype, "key": api_key, "language":"pt-BR"}
    res = []
    try:
        while True:
            r = requests.get(url, params=params, headers=HEADERS, timeout=REQUEST_TIMEOUT_S)
            data = r.json(); res += data.get("results", [])
            tok = data.get("next_page_token")
            if not tok or len(res) >= max_results: break
            time.sleep(2); params["pagetoken"] = tok
    except Exception:
        pass
    out = []
    for it in res[:max_results]:
        loc = it.get("geometry", {}).get("location", {})
        out.append({
            "name": it.get("name"),
            "address": it.get("vicinity"),
            "lat": loc.get("lat"), "lon": loc.get("lng"),
            "source": "google_nearby", "place_id": it.get("place_id"),
            "rating": it.get("rating"), "reviews": it.get("user_ratings_total"),
            "types": it.get("types", [])
        })
    return out

@st.cache_data(ttl=300, show_spinner=False)
def google_place_details(place_id: str, api_key: str) -> Dict:
    if not api_key or not place_id: return {}
    url = "https://maps.googleapis.com/maps/api/place/details/json"
    fields = ",".join([
        "international_phone_number","formatted_phone_number","website",
        "opening_hours","business_status","url","plus_code"
    ])
    params = {"place_id": place_id, "key": api_key, "language":"pt-BR", "fields": fields}
    try:
        r = requests.get(url, params=params, headers=HEADERS, timeout=DETAILS_TIMEOUT_S)
        res = r.json().get("result", {})
        phone = res.get("international_phone_number") or res.get("formatted_phone_number")
        website = res.get("website")
        hours = None
        if isinstance(res.get("opening_hours", {}).get("weekday_text"), list):
            hours = "; ".join(res["opening_hours"]["weekday_text"])
        return {
            "phone": phone, "website": website, "opening_hours": hours,
            "status": res.get("business_status"), "maps_url": res.get("url"),
            "plus_code": res.get("plus_code", {}).get("global_code")
        }
    except Exception:
        return {}

# ================== T√≠tulo / Sidebar ==================
st.title("‚ö° Aurum Lead Mapper ‚Äî prospec√ß√£o geointeligente")
st.caption("Overpass POI ‚Ä¢ Google Nearby + Text ‚Ä¢ Details ‚Ä¢ Dashboard ‚Ä¢ CRM ‚Ä¢ Maiores Telhados")

with st.sidebar:
    st.header("üîß Configura√ß√µes")
    if st.button("üßπ Limpar cache (dados)"):
        st.cache_data.clear()
        st.success("Cache limpo. Rode novamente.")

    with st.form("controls"):
        gkey = st.text_input("Google Places API Key", value=GOOGLE_PLACES_API_KEY, type="password")
        enrich_details = st.checkbox("Enriquecer com telefone/site (Google Details)", value=bool(gkey))
        supplement_nominatim = st.checkbox("Suplemento Nominatim (texto livre)", value=False,
                                           help="Pode trazer extra, mas menos preciso que Overpass.")

        st.markdown("**Regi√£o alvo (texto livre ou 'lat,lon')**")
        custom_location = st.text_input("Local (ex.: 'Niter√≥i' ou '-22.9, -43.1')", "Niter√≥i")
        radius_km = st.slider("Raio de busca (km)", 5, 60, 20, 1)

        st.markdown("**Par√¢metros FV**")
        area_per_kwp = st.number_input("m¬≤ por kWp", 4.0, 10.0, 6.0, 0.1)
        coverage_ratio = st.slider("Fator de cobertura do telhado", 0.3, 0.9, 0.6, 0.05)
        specific_yield = st.number_input("Specific yield (kWh/kWp¬∑ano)", 1100.0, 1900.0, 1500.0, 10.0)

        st.markdown("**Base operacional**")
        base_lat = st.number_input("Base lat", value=-22.8832, format="%.6f")
        base_lon = st.number_input("Base lon", value=-43.1034, format="%.6f")

        st.markdown("**Busca**")
        category = st.selectbox("Categoria", list(CATEGORIES_PRESETS.keys()))
        keywords_default = ", ".join(CATEGORIES_PRESETS[category])
        keywords = st.text_area("Palavras-chave (v√≠rgulas)", value=keywords_default, height=80)
        max_results = st.slider("M√°x. locais por fonte", 10, 120, 100, 10)
        use_google = st.checkbox("Usar Google Places (requer API key)", value=bool(gkey))
        use_osm = st.checkbox("Usar OSM Overpass POI", value=True)

        st.markdown("**Heur√≠stica do telhado (Overpass)**")
        roof_mode = st.selectbox("Escolha", ["largest","nearest","hybrid"])

        st.markdown("**Depura√ß√£o / Performance**")
        fast_mode = st.checkbox("Modo R√°pido (debug)", value=False,
                                help="Limita resultados e desativa Details para evitar travar.")
        overpass_enable = st.checkbox("Usar Overpass p/ telhados (OSM)", value=True)
        per_kw_limit = st.slider("Limite por palavra (p/ fonte)", 5, 60, 40, 5)
        overpass_radius_m = st.slider("Raio Overpass telhado (m)", 50, 400, 220, 10)
        global_time_budget_s = st.slider("Or√ßamento de tempo da busca (s)", 5, 999, 90, 5)

        run_btn = st.form_submit_button("üöÄ Executar mapeamento")

# ================== Execu√ß√£o principal ==================
if run_btn:
    t0 = time.time()
    status = st.status("Iniciando busca‚Ä¶", expanded=True)
    status.update(label="Geocodificando regi√£o alvo‚Ä¶", state="running")

    target = geocode_location(custom_location, gkey if use_google else "")
    lat0, lon0 = target["lat"], target["lon"]
    radius_m = int(radius_km * 1000)

    if fast_mode:
        max_results = min(max_results, 60)
        enrich_details = False

    keys = [k.strip() for k in keywords.split(",") if k.strip()]
    per_kw = per_kw_limit
    seen, results = set(), []

    total_steps = max(1,
        (1 if use_osm else 0) +
        (len(GOOGLE_TYPES_BY_CATEGORY.get(category, [])) if (use_google and gkey) else 0) +
        (len(keys) if (use_google and gkey) else 0) +
        (1 if supplement_nominatim else 0)
    )
    prog = st.progress(0); steps_done = 0

    status.update(label="Coletando locais (OSM ‚Üí Google)‚Ä¶", state="running")

    # 1) OSM primeiro (alto volume)
    if use_osm:
        if time.time() - t0 <= global_time_budget_s:
            try:
                data = overpass_poi_search(lat0, lon0, radius_m, category,
                                           limit=max(per_kw, 100 if not fast_mode else 40))
                for d in data:
                    k = (round(d["lat"],6), round(d["lon"],6), d["name"])
                    if k not in seen:
                        seen.add(k); results.append(d)
            except Exception as e:
                st.warning(f"OSM POI falhou: {e}")
        steps_done += 1; prog.progress(min(1.0, steps_done / total_steps))

    # 2) Google Nearby (types)
    if use_google and gkey:
        gtypes = GOOGLE_TYPES_BY_CATEGORY.get(category, [])
        for gtype in gtypes:
            if time.time() - t0 > global_time_budget_s: 
                status.update(label="Tempo esgotado no Google Nearby; seguindo‚Ä¶", state="error"); break
            try:
                data = google_places_nearby(lat0, lon0, radius_m, gtype=gtype,
                                            max_results=min(per_kw, max_results), api_key=gkey)
                for d in data:
                    k = (round(d["lat"],6), round(d["lon"],6), d["name"])
                    if k not in seen:
                        d["category"] = category; seen.add(k); results.append(d)
            except Exception as e:
                st.warning(f"Google Nearby falhou ({gtype}): {e}")
            steps_done += 1; prog.progress(min(1.0, steps_done / total_steps))
            time.sleep(SLEEP_BETWEEN_QUERIES)

    # 3) Google Text Search (keywords)
    if use_google and gkey and keys:
        for kw in keys:
            if time.time() - t0 > global_time_budget_s:
                status.update(label="Tempo esgotado no Google Text; seguindo‚Ä¶", state="error"); break
            try:
                data = google_places_text_search(
                    f"{kw} near {custom_location}", lat0, lon0, radius_m,
                    max_results=min(per_kw, max_results), api_key=gkey
                )
                for d in data:
                    k = (round(d["lat"],6), round(d["lon"],6), d["name"])
                    if k not in seen:
                        d["category"] = category; seen.add(k); results.append(d)
            except Exception as e:
                st.warning(f"Google Text falhou ('{kw}'): {e}")
            steps_done += 1; prog.progress(min(1.0, steps_done / total_steps))
            time.sleep(SLEEP_BETWEEN_QUERIES)

    # 4) Suplemento Nominatim opcional (texto livre)
    def osm_nominatim_search(keyword: str, lat: float, lon: float, radius_m: int = 5000, limit: int = 50) -> List[Dict]:
        url = "https://nominatim.openstreetmap.org/search"
        params = {"q": keyword, "format": "jsonv2", "limit": limit, "lat": lat, "lon": lon, "radius": radius_m}
        try:
            resp = requests.get(url, params=params, headers=HEADERS, timeout=REQUEST_TIMEOUT_S)
            data = resp.json()
        except Exception:
            return []
        out = []
        for r in data:
            try:
                out.append({
                    "name": r.get("display_name", "").split(",")[0],
                    "address": r.get("display_name"),
                    "lat": float(r.get("lat")), "lon": float(r.get("lon")),
                    "source": "osm_nominatim", "category": category
                })
            except Exception:
                pass
        return out[:limit]

    if supplement_nominatim:
        try:
            extra = osm_nominatim_search(category + " " + custom_location, lat0, lon0, radius_m, limit=50)
            for d in extra:
                k = (round(d["lat"],6), round(d["lon"],6), d["name"])
                if k not in seen:
                    seen.add(k); results.append(d)
        except Exception as e:
            st.warning(f"Nominatim extra falhou: {e}")
        steps_done += 1; prog.progress(min(1.0, steps_done / total_steps))

    st.write(f"üß≠ Locais encontrados (deduplicados): **{len(results)}**")

    # Diagn√≥stico de fontes
    src_count = Counter([r.get("source","?") for r in results])
    st.info("üìä Fontes: " + " | ".join([f"{k}:{v}" for k,v in src_count.items()]) if src_count else "üìä sem itens")

    status.update(label="Enriquecendo (telefone/site)‚Ä¶", state="running")

    # Details (opcional)
    if enrich_details and gkey:
        for i, item in enumerate(results[:min(150, len(results))]):
            if time.time() - t0 > global_time_budget_s:
                status.update(label="Tempo esgotado no Details; seguindo‚Ä¶", state="error"); break
            if item.get("source","").startswith("google") and item.get("place_id"):
                det = google_place_details(item["place_id"], gkey)
                if det:
                    item["phone"] = det.get("phone")
                    item["website"] = det.get("website")
                    item["opening_hours"] = det.get("opening_hours")
                    item["status"] = det.get("status")
                    item["maps_url"] = det.get("maps_url")
                    item["plus_code"] = det.get("plus_code")
            if (i+1) % 12 == 0:
                st.caption(f"‚Ä¶details {i+1} / {min(150, len(results))}")
            time.sleep(0.08)

    status.update(label="Estimando telhados e kWp‚Ä¶", state="running")

    # Estima√ß√£o FV + score
    rows = []
    for i, r in enumerate(results):
        lat, lon = r["lat"], r["lon"]
        buildings = []
        if overpass_enable:
            if time.time() - t0 > global_time_budget_s:
                status.update(label="Tempo esgotado no Overpass telhados; continuar√° sem telhado.", state="error")
                overpass_enable = False
            else:
                try:
                    buildings = overpass_buildings_around(lat, lon, radius_m=overpass_radius_m)
                except Exception:
                    buildings = []

        area_m2 = estimate_rooftop_area_m2(buildings, poi_lat=lat, poi_lon=lon, mode=roof_mode) if buildings else 0.0
        kwp = estimate_kwp(area_m2, area_per_kwp=area_per_kwp, coverage_ratio=coverage_ratio)
        gen = estimate_generation_kwh_year(kwp, specific_yield=specific_yield)
        dist = haversine_km(base_lat, base_lon, lat, lon)
        score = aurum_score(r.get("category", category), area_m2, dist)

        rows.append({
            "Nome": r.get("name"),
            "Telefone": r.get("phone"),
            "Site": r.get("website"),
            "E-mail": r.get("email"),
            "Endere√ßo": r.get("address"),
            "Categoria": r.get("category", category),
            "Fonte": r.get("source"),
            "Rating": r.get("rating"),
            "Reviews": r.get("reviews"),
            "Maps URL": r.get("maps_url"),
            "Latitude": lat, "Longitude": lon,
            "√Årea telhado (m¬≤)": round(area_m2,1),
            "Pot√™ncia estimada (kWp)": round(kwp,1),
            "Gera√ß√£o anual (kWh)": round(gen,0),
            "Dist√¢ncia da base (km)": round(dist,1),
            "Aurum Score": score,
        })

        if (i+1) % 20 == 0:
            st.caption(f"Processados {i+1}/{len(results)}‚Ä¶")

        if time.time() - t0 > global_time_budget_s:
            st.warning(f"Interrompido por or√ßamento de tempo. Processados {i+1} itens.")
            break

    if rows:
        df = pd.DataFrame(rows).sort_values(
            by=["Aurum Score","Pot√™ncia estimada (kWp)","√Årea telhado (m¬≤)"], ascending=False
        )
        st.session_state.df = df
        st.session_state.last_params = {
            "local": custom_location, "raio_km": radius_km, "categoria": category,
            "base_lat": base_lat, "base_lon": base_lon, "roof_mode": roof_mode
        }
        status.update(label="Conclu√≠do ‚úÖ", state="complete")
    else:
        status.update(label="Sem linhas para exibir (veja avisos acima).", state="error")

# ================== Abas (inclui Maiores Telhados) ==================
tab_dash, tab_map, tab_saved, tab_bigroofs = st.tabs(
    ["üìä Dashboard", "üó∫Ô∏è Mapeamento atual", "üì¶ Leads salvos", "üè¢ Maiores Telhados"]
)

# ---------- Dashboard ----------
with tab_dash:
    st.subheader("üìä Vis√£o geral")
    df = st.session_state.df
    if df is None or df.empty:
        st.info("Sem resultados ainda. Execute um mapeamento.")
    else:
        for col, default in [
            ("√Årea telhado (m¬≤)", 0.0),
            ("Pot√™ncia estimada (kWp)", 0.0),
            ("Gera√ß√£o anual (kWh)", 0.0),
            ("Aurum Score", 0.0),
        ]:
            if col not in df.columns: df[col] = default

        c1, c2, c3, c4 = st.columns(4)
        with c1: st.metric("Leads encontrados", len(df))
        with c2: st.metric("kWp total", f"{df['Pot√™ncia estimada (kWp)'].sum():,.0f}".replace(",","."))
        with c3: st.metric("Gera√ß√£o/ano (MWh)", f"{df['Gera√ß√£o anual (kWh)'].sum()/1000:,.1f}".replace(",","."))
        with c4: st.metric("Aurum Score m√©dio", f"{df['Aurum Score'].mean():.1f}")

        st.markdown("**Por categoria**")
        by_cat = df.groupby("Categoria").agg(
            leads=("Nome","count"),
            kwp=("Pot√™ncia estimada (kWp)","sum"),
            score=("Aurum Score","mean")
        ).sort_values("kwp", ascending=False)
        st.dataframe(by_cat, use_container_width=True)

        st.markdown("**Top 10 por Score**")
        st.dataframe(
            df[["Nome","Categoria","Aurum Score","Pot√™ncia estimada (kWp)","Gera√ß√£o anual (kWh)","Endere√ßo"]].head(10),
            use_container_width=True
        )

# ---------- Mapeamento atual ----------
with tab_map:
    st.subheader("üó∫Ô∏è Mapa de Leads")
    df = st.session_state.df
    params = st.session_state.last_params or {}

    if df is not None and not df.empty:
        center_coords = geocode_location(params.get("local","Niter√≥i"))
        m = folium.Map(location=[center_coords["lat"], center_coords["lon"]],
                       zoom_start=11, control_scale=True, tiles="OpenStreetMap")

        folium.Marker([params.get("base_lat", center_coords["lat"]),
                       params.get("base_lon", center_coords["lon"])],
                      popup="Base Operacional", icon=folium.Icon(color="red", icon="home")).add_to(m)

        for _, row in df.iterrows():
            phone_html = f"<a href='tel:{row['Telefone']}'>{row['Telefone']}</a>" if pd.notna(row["Telefone"]) else "‚Äî"
            site_html = f"<a href='{row['Site']}' target='_blank'>site</a>" if pd.notna(row["Site"]) else "‚Äî"
            maps_html = f"<a href='{row['Maps URL']}' target='_blank'>Google Maps</a>" if pd.notna(row["Maps URL"]) else "‚Äî"
            popup = folium.Popup(f"""
                <b>{row['Nome']}</b><br>
                {row['Endere√ßo'] or '‚Äî'}<br>
                Tel: {phone_html} ¬∑ {site_html} ¬∑ {maps_html}<br>
                Cat: {row['Categoria']} ¬∑ Score: {row['Aurum Score']}<br>
                √Årea: {row['√Årea telhado (m¬≤)']} m¬≤ ¬∑ kWp: {row['Pot√™ncia estimada (kWp)']}
            """, max_width=380)
            folium.CircleMarker([row["Latitude"], row["Longitude"]],
                                radius=6, color="#FF8C00", fill=True, fill_color="#FF8C00",
                                popup=popup).add_to(m)
        st_folium(m, width=1200, height=600)

        st.subheader("üìã Tabela (resultado da busca)")
        st.dataframe(df, use_container_width=True)

        # Salvar no banco
        st.markdown("### üíæ Salvar este resultado no banco de leads")
        col1, col2, col3, col4 = st.columns([1,1,1,2])
        with col1:
            campanha = st.text_input("Campanha", value=params.get("local","Aurum RJ"))
        with col2:
            responsavel = st.selectbox("Respons√°vel", ["Matheus","Hans","Vinicius","Aguiar","Carol"])
        with col3:
            estagio = st.selectbox("Est√°gio", ["Novo","Qualificado","Proposta","Negocia√ß√£o","Fechado-Ganho","Fechado-Perdido"], index=0)
        with col4:
            obs = st.text_input("Observa√ß√£o (opcional)", value="")

        if st.button(f"üì• Salvar {len(df)} leads no banco", type="primary"):
            df_to_save = df.copy()
            ts = pd.Timestamp.now(tz="America/Sao_Paulo")
            df_to_save["Campanha"] = campanha
            df_to_save["Respons√°vel"] = responsavel
            df_to_save["Est√°gio"] = estagio
            df_to_save["Obs"] = obs
            df_to_save["Salvo_em"] = ts.strftime("%Y-%m-%d %H:%M:%S")

            if st.session_state.saved_leads is None or st.session_state.saved_leads.empty:
                merged = df_to_save
            else:
                merged = pd.concat([st.session_state.saved_leads, df_to_save], ignore_index=True)

            merged.drop_duplicates(subset=["Nome","Latitude","Longitude"], keep="first", inplace=True)
            st.session_state.saved_leads = merged
            st.success(f"Salvo! Banco agora tem {len(st.session_state.saved_leads)} leads √∫nicos.")

        c1, c2 = st.columns(2)
        with c1:
            st.download_button("‚¨áÔ∏è Exportar resultado atual (CSV)",
                               data=df.to_csv(index=False).encode("utf-8"),
                               file_name="aurum_leads_resultado.csv", mime="text/csv")
        with c2:
            geojson = {
                "type": "FeatureCollection",
                "features": [
                    {"type": "Feature",
                     "geometry": {"type": "Point", "coordinates": [row["Longitude"], row["Latitude"]]},
                     "properties": {k: (v if not isinstance(v, (float, int)) else float(v))
                                    for k, v in row.items() if k not in ["Latitude","Longitude"]}}
                    for _, row in df.iterrows()
                ]
            }
            st.download_button("Exportar GeoJSON",
                               data=json.dumps(geojson, ensure_ascii=False).encode("utf-8"),
                               file_name="aurum_leads.geojson",
                               mime="application/geo+json")
    else:
        st.info("Execute um mapeamento na barra lateral.")

# ---------- Leads salvos ----------
with tab_saved:
    st.subheader("üì¶ Banco de Leads (consolidado)")
    saved = st.session_state.saved_leads
    if saved is None or saved.empty:
        st.info("Ainda n√£o h√° leads salvos. Salve na aba 'Mapeamento atual'.")
    else:
        f1, f2, f3 = st.columns(3)
        with f1:
            filtro_campanha = st.multiselect("Campanha", sorted(saved["Campanha"].dropna().unique().tolist()))
        with f2:
            filtro_resp = st.multiselect("Respons√°vel", sorted(saved["Respons√°vel"].dropna().unique().tolist()))
        with f3:
            filtro_estagio = st.multiselect("Est√°gio", sorted(saved["Est√°gio"].dropna().unique().tolist()))

        df_view = saved.copy()
        if filtro_campanha: df_view = df_view[df_view["Campanha"].isin(filtro_campanha)]
        if filtro_resp: df_view = df_view[df_view["Respons√°vel"].isin(filtro_resp)]
        if filtro_estagio: df_view = df_view[df_view["Est√°gio"].isin(filtro_estagio)]

        st.caption(f"Mostrando {len(df_view)} de {len(saved)} leads.")
        st.dataframe(df_view, use_container_width=True)

        c1, c2, c3 = st.columns(3)
        with c1:
            st.download_button("‚¨áÔ∏è Exportar banco (CSV)",
                               data=df_view.to_csv(index=False).encode("utf-8"),
                               file_name="aurum_leads_banco.csv", mime="text/csv")
        with c2:
            up = st.file_uploader("üì§ Importar/mesclar CSV", type=["csv"])
            if up is not None:
                try:
                    ext = pd.read_csv(up)
                    for col in ["Campanha","Respons√°vel","Est√°gio","Obs","Salvo_em"]:
                        if col not in ext.columns: ext[col] = ""
                    for col in ["Nome","Latitude","Longitude"]:
                        if col not in ext.columns:
                            st.error(f"CSV precisa ter a coluna '{col}'."); ext = None; break
                    if ext is not None:
                        merged = pd.concat([st.session_state.saved_leads, ext], ignore_index=True)
                        merged.drop_duplicates(subset=["Nome","Latitude","Longitude"], keep="first", inplace=True)
                        st.session_state.saved_leads = merged
                        st.success(f"Misturado! Banco total: {len(merged)} leads √∫nicos.")
                except Exception as e:
                    st.error(f"Falha ao importar CSV: {e}")
        with c3:
            if st.button("üß® Limpar banco de leads"):
                st.session_state.saved_leads = None
                st.warning("Banco de leads apagado.")

# ---------- NOVA ABA: Maiores Telhados (com persist√™ncia) ----------
with tab_bigroofs:
    st.subheader("üè¢ Maiores Telhados por Regi√£o (independente do tipo)")

    with st.form("form_big_roofs", clear_on_submit=False):
        # valores default v√™m do estado, se existir
        br_default_center = st.session_state.big_roofs_center or {}
        br_default_params = st.session_state.big_roofs_params or {}

        st.markdown("**Regi√£o alvo (texto livre ou 'lat,lon')**")
        br_location = st.text_input("Local", value=br_default_center.get("name","Niter√≥i"), key="br_location")
        br_radius_km = st.slider("Raio (km)", 2, 50, br_default_params.get("radius_km", 15), 1, key="br_radius_km")
        br_min_area = st.number_input("√Årea m√≠nima do telhado (m¬≤)", min_value=100.0, max_value=100000.0,
                                      value=br_default_params.get("min_area", 800.0), step=50.0, key="br_min_area")
        br_topn = st.slider("Top N", 10, 500, br_default_params.get("topn", 100), 10, key="br_topn")
        persist_toggle = st.checkbox("üîí Manter resultado ao mudar controles", value=True, key="br_persist")
        br_submit = st.form_submit_button("üîé Buscar maiores telhados")

    def rank_roofs(lat: float, lon: float, radius_m: int, min_area_m2: float = 600.0, top_n: int = 100) -> pd.DataFrame:
        buildings = overpass_buildings_geom_region(lat, lon, radius_m=radius_m)
        rows = []
        for poly in buildings:
            a = project_area_m2(poly)
            if a >= min_area_m2:
                c = poly.centroid
                rows.append({"√Årea telhado (m¬≤)": round(a, 1),
                             "Latitude": float(c.y), "Longitude": float(c.x)})
        if not rows:
            return pd.DataFrame(columns=["√Årea telhado (m¬≤)","Latitude","Longitude"])
        df = pd.DataFrame(rows).sort_values("√Årea telhado (m¬≤)", ascending=False)
        return df.head(top_n)

    # SUBMIT ‚Üí calcula e persiste
    if br_submit:
        st.info("Coletando footprints de pr√©dios no OSM e calculando √°reas‚Ä¶")
        # usa a chave do ambiente (se existir); se n√£o, Nominatim cobre
        center = geocode_location(br_location, GOOGLE_PLACES_API_KEY)
        br_lat, br_lon = center["lat"], center["lon"]
        br_radius_m = int(br_radius_km * 1000)

        df_roofs = rank_roofs(br_lat, br_lon, br_radius_m, min_area_m2=br_min_area, top_n=br_topn)

        st.session_state.big_roofs_df = df_roofs
        st.session_state.big_roofs_center = {"lat": br_lat, "lon": br_lon, "name": br_location}
        st.session_state.big_roofs_params = {"radius_km": br_radius_km, "min_area": br_min_area, "topn": br_topn}

    # RENDER ‚Üí usa o estado caso n√£o haja novo submit
    df_roofs = st.session_state.big_roofs_df
    center = st.session_state.big_roofs_center

    if df_roofs is None or center is None or df_roofs.empty:
        st.info("Defina par√¢metros e clique em **Buscar maiores telhados**.")
    else:
        br_lat, br_lon = center["lat"], center["lon"]
        st.markdown("### üó∫Ô∏è Mapa dos maiores telhados")
        m2 = folium.Map(location=[br_lat, br_lon], zoom_start=12, control_scale=True, tiles="OpenStreetMap")
        folium.Marker([br_lat, br_lon], popup=f"Centro: {center.get('name','‚Äî')}", icon=folium.Icon(color="red", icon="home")).add_to(m2)
        for _, row in df_roofs.iterrows():
            popup = folium.Popup(f"√Årea: {row['√Årea telhado (m¬≤)']} m¬≤", max_width=250)
            folium.CircleMarker([row["Latitude"], row["Longitude"]],
                                radius=6, color="#00d084", fill=True, fill_color="#00d084",
                                popup=popup).add_to(m2)
        st_folium(m2, width=1200, height=600)

        st.markdown("### üìã Ranking (maiores primeiro)")
        st.dataframe(df_roofs, use_container_width=True)

        st.markdown("### ‚¨áÔ∏è Exportar")
        c1, c2 = st.columns(2)
        with c1:
            st.download_button("CSV", data=df_roofs.to_csv(index=False).encode("utf-8"),
                               file_name="maiores_telhados.csv", mime="text/csv")
        with c2:
            geojson = {
                "type": "FeatureCollection",
                "features": [
                    {"type":"Feature",
                     "geometry":{"type":"Point","coordinates":[row["Longitude"], row["Latitude"]]},
                     "properties":{"area_m2": float(row["√Årea telhado (m¬≤)"])}}
                    for _, row in df_roofs.iterrows()
                ]
            }
            st.download_button("GeoJSON",
                               data=json.dumps(geojson, ensure_ascii=False).encode("utf-8"),
                               file_name="maiores_telhados.geojson",
                               mime="application/geo+json")

        # Se o usu√°rio quiser comportamento vol√°til, limpamos quando trocar controles (sem novo submit)
        if not persist_toggle and not br_submit:
            st.session_state.big_roofs_df = None
            st.session_state.big_roofs_center = None
            st.session_state.big_roofs_params = None
